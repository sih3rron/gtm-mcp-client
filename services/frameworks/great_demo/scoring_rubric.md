# Command of Message Framework - Scoring Rubric

## Overall Score Interpretation

**9-10 (Exceptional)**
- Masterful execution across all framework components
- Clear evidence of strategic thinking and business impact focus
- Customer is highly engaged and moving toward decision
- All components well-integrated and mutually reinforcing

**7-8 (Strong)**  
- Good execution with minor gaps or missed opportunities
- Most components handled well with clear business value
- Customer shows strong interest and engagement
- Some areas for refinement but overall solid performance

**5-6 (Adequate)**
- Basic framework components covered but lacks depth
- Some business value established but not compelling
- Customer somewhat engaged but not fully convinced
- Significant opportunities for improvement exist

**3-4 (Poor)**
- Major gaps in framework execution
- Minimal business value or urgency established  
- Customer engagement is low or unclear
- Requires substantial improvement across multiple areas

**1-2 (Critical)**
- Framework components largely missing or poorly executed
- No clear business case or value proposition
- Customer disengaged or confused
- Fundamental rework needed

## Component-Level Scoring Guidelines

### 1. Situation (Weight: 15%)

**Excellent (9-10)**
- Comprehensive understanding of customer's current state demonstrated
- Specific details about processes, systems, and organizational structure captured
- Clear documentation of how current approach impacts business operations
- Customer confirms accuracy of situation assessment

**Good (7-8)**
- Good grasp of customer's current situation with most key details
- Some specifics about processes and systems understood
- General understanding of business impact demonstrated
- Minor gaps in situational understanding

**Fair (5-6)**
- Basic understanding of customer situation established
- Limited detail about current processes or systems
- Vague understanding of business impact
- Some important situational elements missing

**Poor (1-4)**
- Little to no understanding of customer's current situation
- Generic assumptions rather than discovered facts
- No clear connection to business operations
- Customer situation largely unexplored

**Key Evidence to Look For:**
- Specific process descriptions
- System and technology details
- Organizational structure understanding
- Current performance metrics or baselines

### 2. Problem (Weight: 20%)

**Excellent (9-10)**
- Specific, quantifiable problems clearly identified and confirmed
- Root causes understood and documented
- Business impact measured in concrete terms (time, cost, revenue)
- Multiple stakeholders' perspectives on problems captured
- Problems connected to strategic business objectives

**Good (7-8)**
- Clear problems identified with some quantification
- Good understanding of business impact with specific examples
- Some root cause analysis demonstrated
- Problems tied to business outcomes

**Fair (5-6)**
- Problems identified but limited quantification
- General business impact understood but lacks specificity
- Surface-level problem definition without deep analysis
- Some connection to business impact demonstrated

**Poor (1-4)**
- Vague or generic problem statements
- No quantification of business impact
- Assumptions about problems rather than discovered issues
- Problems not connected to business outcomes

**Key Evidence to Look For:**
- Specific cost figures or time wastage quantified
- Revenue impact or opportunity cost identified
- Multiple problem dimensions explored (efficiency, quality, compliance, etc.)
- Customer's own words describing pain points

### 3. Solution (Weight: 20%)

**Excellent (9-10)**
- Solution components directly address each identified problem
- Clear demonstration of how solution resolves specific issues
- Solution presented in customer's business language and context
- No extraneous features or capabilities discussed
- Tight alignment between problems and solution elements

**Good (7-8)**
- Most solution elements clearly connected to problems
- Good use of customer language and business context
- Minor inclusion of non-essential features
- Generally strong problem-solution alignment

**Fair (5-6)**
- Some solution elements address identified problems
- Mix of customer language and vendor terminology
- Some features discussed that don't address core problems
- Basic problem-solution connection demonstrated

**Poor (1-4)**
- Solution components poorly connected to problems
- Heavy use of vendor language and technical jargon
- Significant discussion of features that don't solve customer problems
- Weak or unclear problem-solution alignment

**Key Evidence to Look For:**
- Direct statements linking solution features to specific problems
- Use of customer's terminology and metrics
- Focus on business outcomes rather than product features
- No "feature dumping" or discussion of irrelevant capabilities

### 4. Value (Weight: 20%)

**Excellent (9-10)**
- Quantified business benefits with specific financial impact
- Clear ROI calculation or business case presented
- Benefits tied to customer's key performance indicators
- Value realization timeline clearly defined
- Multiple value dimensions explored (efficiency, revenue, risk reduction)

**Good (7-8)**
- Good quantification of benefits with specific examples
- Some financial impact demonstrated
- Benefits connected to business objectives
- Value timeline generally understood

**Fair (5-6)**
- Basic benefit statements with limited quantification
- Some business impact demonstrated but lacks specificity
- General connection to business value
- Value realization timing unclear

**Poor (1-4)**
- Generic or vague benefit statements
- No quantification of business impact
- Benefits not connected to customer's specific situation
- Value proposition unclear or unconvincing

**Key Evidence to Look For:**
- Specific dollar amounts or percentage improvements
- Time savings quantified in hours/days
- Risk mitigation or compliance benefits identified
- Customer acknowledges and validates value calculations

### 5. Measurement (Weight: 15%)

**Excellent (9-10)**
- Clear, specific metrics defined for measuring success
- Baseline measurements established or planned
- Both leading and lagging indicators identified
- Measurement timeline and responsibility assigned
- Customer agrees to measurement approach

**Good (7-8)**
- Good identification of success metrics with some specificity
- Basic baseline understanding established
- Measurement approach generally agreed upon
- Minor gaps in measurement planning

**Fair (5-6)**
- Some success metrics identified but lack clarity
- Limited baseline or measurement planning
- General agreement on measurement need
- Significant gaps in measurement strategy

**Poor (1-4)**
- Vague or missing success metrics
- No baseline or measurement planning
- Customer unclear on how success will be measured
- Measurement not discussed or poorly defined

**Key Evidence to Look For:**
- Specific KPIs or metrics named
- Baseline performance levels established
- Timeline for measurement reviews
- Customer commitment to tracking and reporting

### 6. Value Realization Event (Weight: 10%)

**Excellent (9-10)**
- Specific date or event identified that drives urgency
- Clear understanding of why timing is critical
- Business consequences of delay well understood
- Timeline creates appropriate decision pressure
- Customer confirms urgency and timeline

**Good (7-8)**
- General timeline established with some urgency
- Good understanding of timing importance
- Some consequences of delay identified
- Customer acknowledges timing considerations

**Fair (5-6)**
- Basic timeline discussed but limited urgency
- Some timing considerations identified
- Minimal consequences of delay explored
- Timeline somewhat flexible or unclear

**Poor (1-4)**
- No clear timeline or urgency established
- Timing considerations not explored
- No consequences of delay discussed
- Timeline completely flexible or missing

**Key Evidence to Look For:**
- Specific dates or deadlines mentioned
- Business events that drive timing (budget cycles, compliance dates, etc.)
- Consequences of delayed implementation
- Customer urgency and commitment to timeline

## Scoring Calculation Methods

### Component Score Calculation
Each component should be scored 1-10 based on the criteria above. Use the following approach:
1. Review transcript evidence for each component
2. Assign initial score based on criteria match
3. Adjust based on customer engagement and confirmation
4. Document specific evidence supporting the score

### Overall Score Calculation
**Weighted Average Method:**
- Situation: 15% × score
- Problem: 20% × score  
- Solution: 20% × score
- Value: 20% × score
- Measurement: 15% × score
- Value Realization Event: 10% × score

**Example:**
- Situation: 7 × 0.15 = 1.05
- Problem: 8 × 0.20 = 1.60
- Solution: 6 × 0.20 = 1.20
- Value: 7 × 0.20 = 1.40
- Measurement: 5 × 0.15 = 0.75
- Value Event: 8 × 0.10 = 0.80
- **Total: 6.8**

## Common Scoring Pitfalls

**Over-Scoring (Common Mistakes)**
- Giving credit for sales rep statements without customer confirmation
- Scoring based on assumptions rather than evidence
- Conflating product knowledge with framework execution
- Ignoring lack of customer engagement or pushback

**Under-Scoring (Common Mistakes)**
- Requiring perfection for high scores (9-10 should be achievable)
- Not recognizing subtle but effective framework application
- Focusing on style over substance
- Penalizing for natural conversation flow vs. rigid structure

## Quality Assurance Guidelines

**Evidence Requirements**
- Every score 7+ should have specific transcript citations
- Customer statements should support business impact claims  
- Quantified benefits require customer acknowledgment
- Timeline urgency should be customer-driven, not rep-imposed

**Consistency Checks**
- High overall scores should have consistently strong components
- Low scores should identify specific improvement opportunities
- Score rationale should be clear and defensible
- Analysis should focus on business outcomes, not product features