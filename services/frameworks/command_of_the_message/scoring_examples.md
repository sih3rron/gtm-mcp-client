# Command of the Message - Scoring Examples

## Overview
This document provides real-world scoring examples for the Command of the Message framework. Use these examples to calibrate your scoring and understand what evidence supports different score ranges.

## Component Scoring Examples

### 1. Situation Analysis (Weight: 15%)

#### Excellent Example (Score: 9/10)
**Scenario**: Enterprise software discovery call

**Customer Evidence**:
> **Sarah Mitchell (CTO)**: "We're currently managing our infrastructure across three different cloud providers after the MegaCorp acquisition last year. We have about 2,000 employees across 12 offices, and our IT team of 15 people is struggling to maintain visibility across all these environments."

**Why This Scores High**:
- Specific organizational context (3 cloud providers, recent acquisition)
- Quantified scale (2,000 employees, 12 offices, 15 IT staff)
- Clear operational structure understanding
- Business context that drives current state

#### Poor Example (Score: 3/10)
**Scenario**: Same discovery call, different execution

**Rep Statement**:
> **Rep**: "So you're a technology company that uses cloud services, right?"
> **Customer**: "Yes, we use cloud."
> **Rep**: "Great, and you have some IT challenges?"

**Why This Scores Low**:
- Vague, generic questioning
- No specific organizational context uncovered
- Customer provides minimal detail
- No quantification or business context established

---

### 2. Problem Identification (Weight: 20%)

#### Good Example (Score: 7/10)
**Scenario**: Financial services compliance discussion

**Customer Evidence**:
> **Michael Torres (Compliance Director)**: "Our biggest headache is the manual reporting process. Every month, my team spends about 80 hours compiling data from six different systems. We're always worried about human error, especially with the new regulations that came into effect this quarter. Last month, we had to resubmit a report because of a calculation error."

**Why This Scores Well**:
- Specific problem articulation (manual reporting)
- Quantified impact (80 hours monthly)
- Multiple pain points identified (human error, regulatory pressure)
- Recent evidence of problem (resubmission incident)
- Clear business consequences

#### Excellent Example (Score: 10/10)
**Scenario**: Manufacturing operations call

**Customer Evidence**:
> **Jennifer Park (Operations VP)**: "Our production line downtime is costing us approximately $50,000 per hour. In the last quarter alone, we've had 127 hours of unplanned downtime - that's $6.35 million in lost revenue. The root cause is always the same: we can't predict when equipment will fail because our sensors provide data, but we have no way to analyze patterns. Our maintenance team is essentially reactive, which means we're always playing catch-up. The CEO has made it clear that if we don't solve this by Q4, we're looking at potential layoffs."

**Why This Scores Excellent**:
- Quantified financial impact ($50K/hour, $6.35M quarterly loss)
- Specific operational metrics (127 hours downtime)
- Root cause identification (predictive maintenance gap)
- Organizational consequences (potential layoffs)
- Executive urgency established
- Clear business justification for action

---

### 3. Solution Presentation (Weight: 20%)

#### Fair Example (Score: 5/10)
**Scenario**: CRM software demonstration

**Rep Presentation**:
> **Rep**: "Our CRM system has all the standard features you'd expect - contact management, deal tracking, reporting dashboards. It integrates with most email systems and has mobile apps for your sales team. The reporting module can generate the standard sales reports."

**Customer Response**:
> **Customer**: "Okay, that sounds like what we're looking for."

**Why This Scores Fair**:
- Generic solution presentation
- No connection to specific customer needs
- Features-focused rather than outcome-focused
- Minimal customer engagement or confirmation
- No differentiation from alternatives

#### Excellent Example (Score: 9/10)
**Scenario**: Same CRM software, better execution

**Rep Presentation**:
> **Rep**: "Based on what you've shared about your 47% lead conversion challenge and the disconnect between your marketing and sales teams, let me show you three specific capabilities. First, our lead scoring algorithm would automatically prioritize the 200+ daily leads you mentioned, focusing your reps on the highest-probability prospects. Second, our marketing attribution tracking would solve your 'leads disappearing into a black hole' problem by showing exactly which campaigns generate your best customers. Third, our automated follow-up sequences would handle the 60% of leads that currently get no follow-up, as you mentioned."

**Customer Response**:
> **Lisa Chen (Sales Director)**: "That lead scoring piece is exactly what we need. Can you show me how it would work with our current marketing campaigns?"

**Why This Scores Excellent**:
- Direct connection to stated customer problems
- Quantified customer context referenced (47%, 200+ leads, 60%)
- Solution mapped to specific business outcomes
- Customer engagement and follow-up questions
- Differentiated value proposition

---

### 4. Value Quantification (Weight: 20%)

#### Basic Example (Score: 4/10)
**Scenario**: HR software value discussion

**Rep Statement**:
> **Rep**: "Most of our customers see significant time savings and cost reductions with our platform."

**Customer Response**:
> **Customer**: "That's good to hear."

**Why This Scores Low**:
- Vague, unquantified benefits
- Generic customer references
- No specific value calculation
- No customer validation or engagement

#### Excellent Example (Score: 10/10)
**Scenario**: Same HR software, strong value presentation

**Rep Value Calculation**:
> **Rep**: "Let me walk through the financial impact based on your specific situation. You mentioned your HR team of 8 people spends 15 hours per week on manual onboarding tasks, and you onboard about 25 new employees monthly. That's 780 hours annually at an average loaded cost of $65/hour, or roughly $50,700 in internal costs. Our automation would eliminate 80% of that manual work, saving you approximately $40,560 annually just in time savings."

**Customer Validation**:
> **David Kim (HR Director)**: "Your math is spot-on. Actually, you're being conservative - when Sarah is out sick, onboarding becomes a real bottleneck. Last month, we had two new managers waiting three weeks to get system access. What's the ROI timeline on this investment?"

**Follow-up Value Discussion**:
> **Rep**: "Beyond time savings, you mentioned turnover costs you about $15,000 per employee in recruiting and training. Our employee experience improvements typically reduce first-year turnover by 25-30%. With your current 20% first-year turnover rate on 300 employees, that's preventing 15-18 departures annually, saving another $225,000-$270,000."

**Customer Response**:
> **David Kim**: "If we can hit even half those turnover improvements, this pays for itself in the first year."

**Why This Scores Excellent**:
- Specific calculations using customer's data
- Customer validates and engages with the math
- Multiple value streams identified
- Customer acknowledges ROI potential
- Quantified business case established

---

## Scoring Calculation Example

### Sample Call: Enterprise Security Software

**Component Scores**:
- Situation: 8 (strong organizational context, clear current state)
- Problem: 9 (quantified security incidents, regulatory pressure)
- Solution: 6 (good connection to needs, could be more specific)
- Value: 7 (solid ROI calculation, customer engagement)
- Measurement: 5 (basic metrics discussed, no detailed tracking plan)
- Value Realization Event: 8 (clear compliance deadline driving urgency)

**Weighted Calculation**:
- Situation: 8 × 0.15 = 1.20
- Problem: 9 × 0.20 = 1.80
- Solution: 6 × 0.20 = 1.20
- Value: 7 × 0.20 = 1.40
- Measurement: 5 × 0.15 = 0.75
- Value Event: 8 × 0.10 = 0.80

**Overall Score: 7.15**

## Common Scoring Pitfalls

### Over-Scoring Mistakes

1. **Giving Credit for Rep Statements Without Customer Confirmation**
   - ❌ Rep says "This will save you money" = Value score
   - ✅ Customer says "That ROI makes sense" = Value score

2. **Assumption-Based Scoring**
   - ❌ "They probably have this problem" = Problem score
   - ✅ Customer explicitly states the problem = Problem score

3. **Confusing Product Knowledge with Framework Execution**
   - ❌ Rep demonstrates features well = High solution score
   - ✅ Customer confirms solution addresses their needs = High solution score

### Under-Scoring Mistakes

1. **Requiring Perfect Framework Language**
   - Natural conversation flow can still demonstrate framework mastery

2. **Penalizing Conversational Style**
   - Framework application doesn't need to be rigid or formulaic

3. **Missing Subtle Framework Application**
   - Look for evidence of framework thinking, not just explicit methodology

## Evidence Requirements by Score Range

### Scores 8-10 (Excellent)
- **Required**: Specific customer quotes supporting the score
- **Required**: Quantified business impact or detailed context
- **Required**: Customer engagement and validation
- **Required**: Clear connection to business outcomes

### Scores 6-7 (Good)
- **Required**: Customer confirmation or acknowledgment
- **Recommended**: Some quantification or specific examples
- **Required**: Evidence of framework component addressed

### Scores 4-5 (Fair)
- **Required**: Basic evidence that component was addressed
- **Acceptable**: Limited customer engagement or detail

### Scores 1-3 (Poor)
- **Evidence**: Component not addressed or poorly executed
- **Typical**: Generic statements, no customer engagement

## Template for Scoring Documentation

```markdown
### Component: [Component Name]
**Score**: [1-10]

**Evidence**:
> **[Speaker Name] ([Title])**: "[Exact customer quote]"

**Rationale**: [Why this evidence supports the score]

**Improvement Opportunity**: [If score <8, what could be better]
```

## Quality Assurance Checklist

- [ ] Every score 7+ has supporting customer quotes
- [ ] Customer statements support business impact claims
- [ ] Quantified benefits have customer acknowledgment
- [ ] Timeline urgency is customer-driven, not rep-imposed
- [ ] Overall score aligns with component scores
- [ ] Analysis focuses on business outcomes, not product features